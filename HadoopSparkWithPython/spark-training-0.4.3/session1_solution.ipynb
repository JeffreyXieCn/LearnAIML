{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"background:black\">\n",
    "    <center>\n",
    "<img src=\"./images/session1/title.png\" alt=\"Title\"/>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<center>At the end of this session, you will know:</center>\n",
    "\n",
    "&#x25a2; _when_ to use Spark\n",
    "\n",
    "&#x25a2; _how_ to write Spark programs\n",
    "\n",
    "&#x25a2; what is the relation between Spark and _Hadoop_\n",
    "</div>\n",
    "\n",
    "<p style=\"float: left; font-size: 9pt; text-align: center; width: 30%; margin-right: 30%; margin-bottom: 0.5em;\"><a href=\"http://spark.apache.org\"><img src=\"http://spark.apache.org/images/spark-logo-trademark.png\" width=150></a></p>\n",
    "<p style=\"float: left; font-size: 9pt; text-align: center; width: 30%; margin-right: 1%; margin-bottom: 0.5em;\"><a href=\"http://hadoop.apache.org\"><img src=\"https://hadoop.apache.org/hadoop-logo.jpg\" width=290></a></p>\n",
    "<p style=\"clear: both;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Goal:</b> process large datasets easily and efficiently \n",
    "</div>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Key concept 1: Resilient Distributed Datasets (RDDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<center>Apache Spark is built around a data structure: the <b>Resilient Distributed Dataset (RDD)</b></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "\n",
    "## Why distributed?\n",
    "\n",
    "<a href=\"https://www.google.com/about/datacenters/gallery/\">\n",
    "<img src=\"https://lh3.googleusercontent.com/_T5y2eKUusOWBn44MkgTDc1EQVsiGkvWXDDgbNZxeKOp1aHKYpIMS56JhU3esg6F_V6sbmGmxmThuk5ugETygfPdv2ssbVRjHD3fcw=w800-l80-sg-rj-c0xffffff\" alt=\"google data center\"/></a>\n",
    "\n",
    "Photo (c) Google\n",
    "    \n",
    "```\n",
    "Our Council Bluffs, Iowa data center provides over 115,000 square feet of space. We make the best out of every inch, so you can use services like Search and YouTube in the most efficient way possible.\n",
    "```\n",
    "   </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<center>\n",
    "    <b>Cluster architecture</b>\n",
    "    <img src=\"./images/session1/cluster-architecture.png\" alt=\"cluster architecture\"/>\n",
    "    adapted from <a href=\"htttp://mmds.org\">http://mmds.org</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<center>An RDD can be distributed among many cluster nodes, aggregating CPU, memory and disk resources.</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "## Why resilient?\n",
    "\n",
    "<a href=\"https://www.google.com/about/datacenters/gallery/\">\n",
    "    <img src=\"https://lh3.googleusercontent.com/0N2MQjMcGLlmHE4p-0FRdsKUyKieC-ga0UtW5HVDB1HHBbmiRj2kA2TCDgyWaK2ZzvrKpWoI4c1djmRi0I-ujnNCo43qpQp7e4q3TA=w800-l80-sg-rj-c0xffffff\" alt=\"data center 1\"/>\n",
    " </a>\n",
    "\n",
    "Photo (c) Google\n",
    "    \n",
    "```\n",
    "Blue LEDs on this row of servers in our Douglas County, Georgia data center tell us everything is running smoothly. We use LEDs because they are energy efficient, long lasting and bright.\n",
    "```\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <b>The Hadoop Distributed File System (HDFS)</b>\n",
    "<img src=\"images/session1/hdfs.png\"/>\n",
    "    adapted from <a href=\"htttp://mmds.org\">http://mmds.org</a>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>An RDD can be stored on HDFS, where data chunks are <b>replicated</b> across nodes.</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <b>File reads</b>\n",
    "<img src=\"images/session1/hdfs2.png\"/>\n",
    "    Source: Hadoop: The Definitive Guide, Tom White, 4th edition.\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <b>File writes</b>\n",
    "<img src=\"images/session1/hdfs1.png\"/>\n",
    "    Source: Hadoop: The Definitive Guide, Tom White, 4th edition.\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<center>An RDD can also be <b>recomputed</b>, as it stores its own lineage.</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"images/session1/lineage.png\"/>\n",
    "<a href=\"https://dl.acm.org/doi/fullHtml/10.1145/2934664\">[Zaharia <i>et al.</i>, 2016]</a>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating RDDs\n",
    "\n",
    "Before we can create and manipulate RDDs, let's make sure that Apache Spark is properly installed. Spark comes with APIs in four languages: Java, Scala, R and Python. Here we will use the Python API.\n",
    "\n",
    "`pyspark` is the Python package that provides Spark's Python API. Make sure that version 3.0.0 is properly installed on your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! pip freeze | grep pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# A little magic to adjust the config at Ericsson\n",
    "import os\n",
    "os.environ[\"IPYTHON\"]=\"1\"\n",
    "#os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"C:\\\\ProgramData\\\\Anaconda3\\\\python.exe\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"ipython3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]=\"notebook\"\n",
    "#os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/default-java\"\n",
    "os.environ[\"JAVA_HOME\"]=\"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_202\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In Spark, many functions are provided through a helper object called the Spark context. A Spark context can be created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Spark context\n",
    "from pyspark.context import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "RDDs can be created in three ways:\n",
    "\n",
    "(1) From an existing Python list, using function <code>parallelize</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[8] at readRDDFromFile at PythonRDD.scala:262"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create \"numbers\", an RDD defined from a Python list\n",
    "numbers = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The content of an RDD can be inspected using <b>actions</b> such as `collect`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the RDD back to a Python list, for inspection\n",
    "numbers.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Warning:</b> actions can be very dangerous!\n",
    "    </div>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(2) RDDs can also be created from a file, using `textFile`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a text file in an RDD where each element is a line of the file\n",
    "words = sc.textFile('data/session1/words.txt')\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>: <code>textFile</code> can also read data from HDFS\n",
    "        </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(3) Or from an existing RDD, using a <b>transformation</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 5, 7, 8, 10]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random sample with 50% of the data\n",
    "sample = numbers.sample(fraction=0.5, withReplacement=False)\n",
    "sample.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Manipulating RDDs\n",
    "\n",
    "RDDs are manipulated using <b>transformations</b> and <b>actions</b>:\n",
    "\n",
    "<a href=\"http://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations\"><img src=\"images/session1/transformations-actions.png\" alt=\"Transformations and actions\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Several transformations, such as `filter`, take a function as argument. This function can be either explicitly defined, or defined in the argument of the transformation as an anonymous (aka \"lambda\") function.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function definition\n",
    "def even(x):\n",
    "    '''\n",
    "    Return True if x is an even integer\n",
    "    '''\n",
    "    return x % 2 == 0\n",
    "\n",
    "# Extracts the even numbers from RDD \"numbers\"\n",
    "even = numbers.filter(even)\n",
    "\n",
    "# Note: each partition of an RDD can be processed independently using filter\n",
    "\n",
    "even.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same operation, now with the function declared as a lambda function\n",
    "even = numbers.filter(lambda x: x % 2 == 0)\n",
    "even.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "<li>Create an RDD that contains the words in <code>words</code> that have four letters or more.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three', 'four', 'five', 'seven', 'eight']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_words = words.filter(lambda x: len(x) >= 4)\n",
    "long_words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use-case (part 1): Open Data from the City of Montreal\n",
    "\n",
    "We will study <a href=\"http://donnees.ville.montreal.qc.ca/dataset/frenes-publics-proteges-injection-agrile-du-frene \">this dataset</a>, provided by the city of Montreal. \n",
    "\n",
    "The dataset contains \n",
    "the list of trees treated against the <a href=\"https://en.wikipedia.org/wiki/Emerald_ash_borer\">emerald ash borer</a> in Montreal.\n",
    "\n",
    "We will use the 2015 and 2016 data sets also available in directory `data` made available with this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<center>Our goal is to use Spark to extract basic statistics about the dataset.</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As CSV files, these datasets can be read by many libraries, such as `Pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom_arrond</th>\n",
       "      <th>Invent</th>\n",
       "      <th>No_Civiq</th>\n",
       "      <th>Rue</th>\n",
       "      <th>Rue_De</th>\n",
       "      <th>Rue_a</th>\n",
       "      <th>Nom_parc</th>\n",
       "      <th>Sigle</th>\n",
       "      <th>Injections</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahuntsic-Cartierville</td>\n",
       "      <td>R</td>\n",
       "      <td>10265</td>\n",
       "      <td>Rue Saint-Hubert</td>\n",
       "      <td>SAURIOL E RUE</td>\n",
       "      <td>FLEURY E RUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRPESU</td>\n",
       "      <td>2015</td>\n",
       "      <td>292338.7500</td>\n",
       "      <td>5.046268e+06</td>\n",
       "      <td>-73.659611</td>\n",
       "      <td>45.556217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahuntsic-Cartierville</td>\n",
       "      <td>R</td>\n",
       "      <td>9451</td>\n",
       "      <td>Rue Foucher</td>\n",
       "      <td>CHABANEL E RUE</td>\n",
       "      <td>LOUVAIN E RUE DE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRAMKL</td>\n",
       "      <td>2015</td>\n",
       "      <td>293090.7190</td>\n",
       "      <td>5.045716e+06</td>\n",
       "      <td>-73.649967</td>\n",
       "      <td>45.551254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahuntsic-Cartierville</td>\n",
       "      <td>R</td>\n",
       "      <td>10435</td>\n",
       "      <td>Rue Taché</td>\n",
       "      <td>TACHÉ PLACE</td>\n",
       "      <td>PRIEUR E RUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>292521.6820</td>\n",
       "      <td>5.047302e+06</td>\n",
       "      <td>-73.657294</td>\n",
       "      <td>45.565520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahuntsic-Cartierville</td>\n",
       "      <td>R</td>\n",
       "      <td>1475</td>\n",
       "      <td>Rue Prieur Est</td>\n",
       "      <td>OLYMPIA BOULE</td>\n",
       "      <td>HAMEL AVENU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>292325.8971</td>\n",
       "      <td>5.047060e+06</td>\n",
       "      <td>-73.659796</td>\n",
       "      <td>45.563336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahuntsic-Cartierville</td>\n",
       "      <td>R</td>\n",
       "      <td>9905</td>\n",
       "      <td>Avenue du Sacré-Coeur</td>\n",
       "      <td>SAUVÉ E RUE</td>\n",
       "      <td>SAURIOL E RUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>292839.2650</td>\n",
       "      <td>5.046594e+06</td>\n",
       "      <td>-73.653208</td>\n",
       "      <td>45.559155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21909</th>\n",
       "      <td>PARCS-NATURE</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONT-ROYAL</td>\n",
       "      <td>FR</td>\n",
       "      <td>2015</td>\n",
       "      <td>297437.7404</td>\n",
       "      <td>5.039934e+06</td>\n",
       "      <td>-73.594205</td>\n",
       "      <td>45.499286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21910</th>\n",
       "      <td>PARCS-NATURE</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONT-ROYAL</td>\n",
       "      <td>FR</td>\n",
       "      <td>2015</td>\n",
       "      <td>297561.8105</td>\n",
       "      <td>5.041163e+06</td>\n",
       "      <td>-73.592636</td>\n",
       "      <td>45.510347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21911</th>\n",
       "      <td>PARCS-NATURE</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONT-ROYAL</td>\n",
       "      <td>FR</td>\n",
       "      <td>2015</td>\n",
       "      <td>297647.5074</td>\n",
       "      <td>5.041122e+06</td>\n",
       "      <td>-73.591539</td>\n",
       "      <td>45.509982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21912</th>\n",
       "      <td>PARCS-NATURE</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONT-ROYAL</td>\n",
       "      <td>FR</td>\n",
       "      <td>2015</td>\n",
       "      <td>297635.0479</td>\n",
       "      <td>5.041121e+06</td>\n",
       "      <td>-73.591698</td>\n",
       "      <td>45.509975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21913</th>\n",
       "      <td>PARCS-NATURE</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONT-ROYAL</td>\n",
       "      <td>FR</td>\n",
       "      <td>2015</td>\n",
       "      <td>297636.1543</td>\n",
       "      <td>5.041125e+06</td>\n",
       "      <td>-73.591684</td>\n",
       "      <td>45.510005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21914 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Nom_arrond Invent No_Civiq                    Rue  \\\n",
       "0      Ahuntsic-Cartierville      R    10265       Rue Saint-Hubert   \n",
       "1      Ahuntsic-Cartierville      R     9451            Rue Foucher   \n",
       "2      Ahuntsic-Cartierville      R    10435              Rue Taché   \n",
       "3      Ahuntsic-Cartierville      R     1475         Rue Prieur Est   \n",
       "4      Ahuntsic-Cartierville      R     9905  Avenue du Sacré-Coeur   \n",
       "...                      ...    ...      ...                    ...   \n",
       "21909           PARCS-NATURE      H      NaN                    NaN   \n",
       "21910           PARCS-NATURE      H      NaN                    NaN   \n",
       "21911           PARCS-NATURE      H      NaN                    NaN   \n",
       "21912           PARCS-NATURE      H      NaN                    NaN   \n",
       "21913           PARCS-NATURE      H      NaN                    NaN   \n",
       "\n",
       "               Rue_De             Rue_a    Nom_parc   Sigle  Injections  \\\n",
       "0       SAURIOL E RUE      FLEURY E RUE         NaN  FRPESU        2015   \n",
       "1      CHABANEL E RUE  LOUVAIN E RUE DE         NaN  FRAMKL        2015   \n",
       "2         TACHÉ PLACE      PRIEUR E RUE         NaN    FRPE        2015   \n",
       "3       OLYMPIA BOULE       HAMEL AVENU         NaN    FRPE        2015   \n",
       "4         SAUVÉ E RUE     SAURIOL E RUE         NaN    FRPE        2015   \n",
       "...               ...               ...         ...     ...         ...   \n",
       "21909             NaN               NaN  MONT-ROYAL      FR        2015   \n",
       "21910             NaN               NaN  MONT-ROYAL      FR        2015   \n",
       "21911             NaN               NaN  MONT-ROYAL      FR        2015   \n",
       "21912             NaN               NaN  MONT-ROYAL      FR        2015   \n",
       "21913             NaN               NaN  MONT-ROYAL      FR        2015   \n",
       "\n",
       "                 x             y  longitude   latitude  \n",
       "0      292338.7500  5.046268e+06 -73.659611  45.556217  \n",
       "1      293090.7190  5.045716e+06 -73.649967  45.551254  \n",
       "2      292521.6820  5.047302e+06 -73.657294  45.565520  \n",
       "3      292325.8971  5.047060e+06 -73.659796  45.563336  \n",
       "4      292839.2650  5.046594e+06 -73.653208  45.559155  \n",
       "...            ...           ...        ...        ...  \n",
       "21909  297437.7404  5.039934e+06 -73.594205  45.499286  \n",
       "21910  297561.8105  5.041163e+06 -73.592636  45.510347  \n",
       "21911  297647.5074  5.041122e+06 -73.591539  45.509982  \n",
       "21912  297635.0479  5.041121e+06 -73.591698  45.509975  \n",
       "21913  297636.1543  5.041125e+06 -73.591684  45.510005  \n",
       "\n",
       "[21914 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/session1/frenepublicinjection2015.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <center><b>Note:</b> We could use Pandas instead of Spark to analyze this dataset, but it wouldn't scale to larger datasets.</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To start with, let's load this dataset in Spark, using Python's CSV module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Nom_arrond',\n",
       "  'Invent',\n",
       "  'No_Civiq',\n",
       "  'Rue',\n",
       "  'Rue_De',\n",
       "  'Rue_a',\n",
       "  'Nom_parc',\n",
       "  'Sigle',\n",
       "  'Injections',\n",
       "  'x',\n",
       "  'y',\n",
       "  'longitude',\n",
       "  'latitude'],\n",
       " ['Ahuntsic-Cartierville',\n",
       "  'R',\n",
       "  '10265',\n",
       "  'Rue Saint-Hubert',\n",
       "  'SAURIOL E RUE',\n",
       "  'FLEURY E RUE',\n",
       "  '',\n",
       "  'FRPESU',\n",
       "  '2015',\n",
       "  '292338.75000000000',\n",
       "  '5046268.50000000000',\n",
       "  '-73.6596113879546',\n",
       "  '45.5562169952192']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename2015 = 'data/session1/frenepublicinjection2015.csv'\n",
    "\n",
    "def read_data_file(filename):\n",
    "    import csv\n",
    "    # Load the text file as an RDD, where each element is a line\n",
    "    rdd = sc.textFile(filename)\n",
    "    # Use Python's CSV reader to map every line of the text file to a Python list\n",
    "    trees = rdd.mapPartitions(lambda x: csv.reader(x))\n",
    "    return trees\n",
    "    \n",
    "# Show the first two elements of the RDD, with action \"take\"\n",
    "read_data_file(filename2015).take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Print the number of trees that were treated in 2015 and 2016. Tip: use the <code>count</code> action.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21915\n",
      "27245\n"
     ]
    }
   ],
   "source": [
    "filename2016 = 'data/session1/frenepublicinjection2016.csv'\n",
    "\n",
    "trees2015 = read_data_file(filename2015)\n",
    "trees2016 = read_data_file(filename2016)\n",
    "\n",
    "print(trees2015.count())\n",
    "print(trees2016.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Print the number of trees in park <code>BEAUBIEN</code> that were treated in 2015. Tip: use the <code>filter</code> action on column <code>Nom_parc</code> (index: 6)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees2015.filter(lambda x: x[6] == 'BEAUBIEN').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "A Spark implementation of a data analysis will always be faster than a Pandas implementation of the same analysis:\n",
    "    \n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x25a2; False\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "A Spark implementation of a data analysis will always be faster than a Pandas implementation of the same analysis:\n",
    "    \n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x2611; False\n",
    "</div>\n",
    "\n",
    "Spark has overheads, due to:\n",
    "- The need to transfer data between computing nodes\n",
    "- The Spark framework itself\n",
    "\n",
    "Pandas will be faster when:\n",
    "- Data fits in memory\n",
    "- Processing is limited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Writing a Spark program requires detailed knowledge of cluster computing:\n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x25a2; False\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Writing a Spark program requires detailed knowledge of cluster computing:\n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x2611; False\n",
    "</div>\n",
    "\n",
    "Spark's APIs decouple the analysis logic from its distributed execution on a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Spark analyses are limited to basic data queries:  \n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x25a2; False\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Spark analyses are limited to basic data queries:  \n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x2611; False\n",
    "</div>\n",
    "\n",
    "Spark has rich APIs for data analysis, data mining, machine learning and data stream analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Key concept 2: MapReduce\n",
    "\n",
    "\n",
    "MapReduce is arguably the most famous and powerful <b>programming model</b> for Big Data analysis. \n",
    "\n",
    "Introduced by <a href=\"https://dl.acm.org/doi/abs/10.1145/1327452.1327492?casa_token=DCf_01yMfcQAAAAA:lOY3pLjhcDj4YPtDqowe7zcsZd3bpqgqZW8x0KYaadjEPFas7Id1O4g4t6idEAVUeS2ebaeyFumGkw\">Google in 2008</a>, it is available in Spark through the `map` and `reduceByKey` transformations.\n",
    "\n",
    "## Map\n",
    "\n",
    "`map` is a transformation that evaluates a function on each element of an RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ONE', 'TWO', 'THREE', 'FOUR', 'FIVE']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper = words.map(lambda x: x.upper())\n",
    "upper.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Create an RDD that contains the square roots of the numbers in RDD <code>numbers</code>.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.4142135623730951,\n",
       " 1.7320508075688772,\n",
       " 2.0,\n",
       " 2.23606797749979,\n",
       " 2.449489742783178,\n",
       " 2.6457513110645907,\n",
       " 2.8284271247461903,\n",
       " 3.0,\n",
       " 3.1622776601683795]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrts = numbers.map(sqrt)\n",
    "sqrts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reduce\n",
    "\n",
    "A reduce operation works on __key-value pairs__.\n",
    "\n",
    "Transformation `groupByKey` groups key-value pairs by key.\n",
    "\n",
    "For instance, when applied to:\n",
    "\n",
    "`[ ('apple', 3), ('banana', 2), ('apple', 7), ('banana', 5) ]`, \n",
    "\n",
    "`groupByKey` returns:\n",
    "\n",
    "`[ ('apple', [ 3, 7 ]), ('banana', [2, 5]) ]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', [3, 7]), ('banana', [2, 5])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create RDD\n",
    "fruits = [ ('apple', 3), ('banana', 2), ('apple', 7), ('banana', 5) ]\n",
    "fruits_rdd = sc.parallelize(fruits)\n",
    "\n",
    "# Apply groupByKey\n",
    "group = fruits_rdd.groupByKey()\n",
    "\n",
    "# Map values to list to display\n",
    "group.mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Spark transformation `reduceByKey` groups key-value pairs by key, and applies a binary aggregation function to the list of values associated with a key.\n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', 3), ('banana', 2), ('apple', 7), ('banana', 5)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', 10), ('banana', 7)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add all the values associated with a key\n",
    "fruits_rdd.reduceByKey(lambda x, y: x+y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "MapReduce is an extremely <b>versatile</b> programming model: any distributed program can be implemented using map and reduce operations.\n",
    "</div>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "WordCount is the historical MapReduce example, aiming at counting the occurrence of words in a document. For instance, if the document contains ten occurrences of the word \"house\", the result returned by WordCount will contain (\"house\", 10).\n",
    "    </div>\n",
    "    </center>\n",
    "    \n",
    "The MapReduce WordCount implementation is based on the following principle:\n",
    "1. Create an RDD where each element is a word in the input document\n",
    "2. Use the `map` transformation to create an RDD containing `(word, 1)` for every word in the document\n",
    "3. Use the `reduceByKey` action to sum the 1s associated with a given word.\n",
    "\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "<li>Implement a WordCount program in Spark to count the occurence of words in file <code>data/places.txt</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mercier-Hochelaga-Maisonneuve', 3102),\n",
       " ('Rivière-des-Prairies - Pointe-aux-Trembles', 752),\n",
       " ('Verdun', 183),\n",
       " ('Ville-Marie', 159),\n",
       " ('Lachine', 216),\n",
       " ('Île-Bizard-Sainte-Geneviève', 28),\n",
       " ('Montréal-Nord', 124),\n",
       " ('Outremont', 252),\n",
       " ('PARCS-NATURE', 780),\n",
       " ('Ahuntsic-Cartierville', 1748),\n",
       " ('Côte-des-Neiges-Notre-Dame-de-Grâce', 1888),\n",
       " ('Lasalle', 149),\n",
       " ('Le Sud-Ouest', 3005),\n",
       " ('Pierrefonds - Roxboro', 358),\n",
       " ('Le Plateau-Mont-Royal', 1806),\n",
       " ('Rosemont - La Petite-Patrie', 2618),\n",
       " ('Saint-Laurent', 819),\n",
       " ('Saint-Léonard', 354),\n",
       " ('Villeray-Saint-Michel - Parc-Extension', 3284),\n",
       " ('Anjou', 289)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/session1/places.txt'\n",
    "places = sc.textFile(filename)\n",
    "\n",
    "places.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x+y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise (optional): Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    An <b>inverted index</b> is a data structure that, given a set of text documents, returns for each word the set of documents in which it occurs. It is the basic structure used in a <b>Web search engine</b>, and a key historical motivation for Google to develop MapReduce.\n",
    "    </div>\n",
    "    </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Assume that an RDD <code>docs_and_words</code> exists that contains pairs <code>doc,word</code> where <code>doc</code> identifies a document and <code>word</code> is a word contained in this document. The following code generates such an RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canada.txt', 'canada'), ('canada.txt', 'is'), ('canada.txt', 'a')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Countries for which a document exists in data/sesssion1/docs\n",
    "countries = ('canada', 'usa', 'mexico')\n",
    "# Initialize an empty RDD.\n",
    "docs_and_words = sc.emptyRDD()\n",
    "# Iterate over documents\n",
    "for country in countries:\n",
    "    file = f'data/session1/docs/{country}.txt'\n",
    "    \n",
    "    # Get all the words in the document, in the form of (doc,word) pairs\n",
    "    words = sc.textFile(file)\\\n",
    "              .flatMap(lambda x: x.split(' '))\\\n",
    "              .map(lambda x: (country+'.txt', x.lower()))\n",
    "    \n",
    "    # Add to the list of docs_and_words\n",
    "    docs_and_words = docs_and_words.union(words)\n",
    "# Check result\n",
    "docs_and_words.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Transform <code>docs_and_words</code> into an inverted index containing pairs of the form <code>word,[docs]</code>, where <code>[docs]</code> is the list of documents that contain <code>words</code>. Sort the inverted index by key (word). Tip: to remove duplicates in a Python list, use a <a href=\"https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset\"><code>set</code></a> instead.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('(3.85', ['canada.txt']),\n",
       " ('(5,525', ['canada.txt']),\n",
       " ('(761,610', ['mexico.txt']),\n",
       " ('(9.8', ['usa.txt']),\n",
       " ('(about', ['mexico.txt']),\n",
       " ('(gdp).[25]', ['usa.txt']),\n",
       " ('(oas),', ['usa.txt']),\n",
       " ('(spanish:', ['mexico.txt']),\n",
       " ('(u.s.', ['usa.txt']),\n",
       " ('(un),', ['mexico.txt']),\n",
       " ('(usa),', ['usa.txt']),\n",
       " ('(wto),', ['mexico.txt']),\n",
       " ('1,972,550', ['mexico.txt']),\n",
       " ('10th-most', ['mexico.txt']),\n",
       " ('11', ['usa.txt']),\n",
       " ('11th-largest', ['mexico.txt']),\n",
       " ('12,000', ['usa.txt']),\n",
       " ('120,000', ['mexico.txt']),\n",
       " ('128,649,565', ['mexico.txt']),\n",
       " ('13th-largest', ['mexico.txt']),\n",
       " ('1521,', ['mexico.txt']),\n",
       " ('15th-largest', ['mexico.txt']),\n",
       " ('16th', ['canada.txt', 'usa.txt']),\n",
       " ('1763.', ['canada.txt']),\n",
       " ('1775', ['usa.txt']),\n",
       " ('1783,', ['usa.txt']),\n",
       " ('1821.[16]', ['mexico.txt']),\n",
       " ('1836', ['mexico.txt']),\n",
       " ('1848,', ['usa.txt']),\n",
       " ('1857.', ['mexico.txt']),\n",
       " ('1867,', ['canada.txt']),\n",
       " ('18th', ['usa.txt']),\n",
       " ('1910', ['mexico.txt']),\n",
       " ('1917', ['mexico.txt']),\n",
       " ('1920s', ['mexico.txt']),\n",
       " ('1928', ['mexico.txt']),\n",
       " ('1929,', ['mexico.txt']),\n",
       " ('1931', ['canada.txt']),\n",
       " ('1969', ['usa.txt']),\n",
       " ('1982,', ['canada.txt']),\n",
       " ('1991', ['usa.txt']),\n",
       " ('19th', ['usa.txt']),\n",
       " ('2000.[17][18][19][20]', ['mexico.txt']),\n",
       " ('2006,', ['mexico.txt']),\n",
       " ('2018,', ['mexico.txt']),\n",
       " ('2019', ['usa.txt']),\n",
       " ('29.4%', ['usa.txt']),\n",
       " ('3.8', ['usa.txt']),\n",
       " ('31', ['mexico.txt']),\n",
       " ('328', ['usa.txt']),\n",
       " ('39', ['mexico.txt']),\n",
       " ('4.3%', ['usa.txt']),\n",
       " ('50', ['usa.txt']),\n",
       " ('5th', ['mexico.txt']),\n",
       " ('6th', ['mexico.txt']),\n",
       " ('76th', ['mexico.txt']),\n",
       " ('7th', ['mexico.txt']),\n",
       " ('8,000', ['mexico.txt']),\n",
       " ('8,891', ['canada.txt']),\n",
       " ('9.98', ['canada.txt']),\n",
       " ('[esˈtaðos', ['mexico.txt']),\n",
       " ('[ˈmexiko]', ['mexico.txt']),\n",
       " ('a', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('abolition.[22][23]', ['usa.txt']),\n",
       " ('abundant', ['canada.txt']),\n",
       " ('accounts', ['usa.txt']),\n",
       " ('accretion', ['canada.txt']),\n",
       " ('acquiring', ['usa.txt']),\n",
       " ('across', ['usa.txt']),\n",
       " ('act', ['canada.txt']),\n",
       " ('admitting', ['usa.txt']),\n",
       " ('advanced', ['canada.txt', 'mexico.txt']),\n",
       " ('after', ['mexico.txt']),\n",
       " ('against', ['mexico.txt']),\n",
       " ('ago,[19]', ['usa.txt']),\n",
       " ('agreement', ['canada.txt']),\n",
       " ('all', ['canada.txt']),\n",
       " ('alliance', ['mexico.txt']),\n",
       " ('along', ['canada.txt', 'usa.txt']),\n",
       " ('although', ['usa.txt']),\n",
       " ('alvaro', ['mexico.txt']),\n",
       " ('america', ['canada.txt', 'usa.txt']),\n",
       " ('america,', ['usa.txt']),\n",
       " ('america.', ['canada.txt', 'mexico.txt']),\n",
       " ('american', ['canada.txt', 'usa.txt']),\n",
       " ('americans', ['usa.txt']),\n",
       " ('americans,', ['usa.txt']),\n",
       " ('americas', ['mexico.txt']),\n",
       " ('among', ['canada.txt', 'mexico.txt']),\n",
       " ('an', ['canada.txt', 'mexico.txt']),\n",
       " ('analysts.[21][22][23][24]', ['mexico.txt']),\n",
       " ('and', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('any', ['usa.txt']),\n",
       " ('apollo', ['usa.txt']),\n",
       " ('approximately', ['mexico.txt', 'usa.txt']),\n",
       " ('arctic', ['canada.txt']),\n",
       " ('are', ['canada.txt', 'usa.txt']),\n",
       " ('area,', ['mexico.txt']),\n",
       " ('area.', ['canada.txt']),\n",
       " ('area.[e]', ['usa.txt']),\n",
       " ('areas', ['canada.txt', 'mexico.txt']),\n",
       " ('armed', ['canada.txt']),\n",
       " ('arrivals.[38]', ['mexico.txt']),\n",
       " ('as', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('asia-pacific', ['canada.txt']),\n",
       " ('assassination', ['mexico.txt']),\n",
       " ('at', ['canada.txt', 'usa.txt']),\n",
       " ('atlantic', ['canada.txt']),\n",
       " ('autonomy', ['canada.txt']),\n",
       " ('average', ['usa.txt']),\n",
       " ('aztecs.', ['mexico.txt']),\n",
       " ('bank,', ['usa.txt']),\n",
       " ('base', ['mexico.txt']),\n",
       " ('bc', ['mexico.txt']),\n",
       " ('became', ['mexico.txt']),\n",
       " ('been', ['usa.txt']),\n",
       " ('before', ['canada.txt']),\n",
       " ('began', ['canada.txt', 'usa.txt']),\n",
       " ('beginning', ['canada.txt', 'usa.txt']),\n",
       " ('being', ['mexico.txt']),\n",
       " ('belize,', ['mexico.txt']),\n",
       " ('benito', ['mexico.txt']),\n",
       " ('between', ['mexico.txt', 'usa.txt']),\n",
       " ('bi-national', ['canada.txt']),\n",
       " ('bilingual', ['canada.txt']),\n",
       " ('biodiversity.[37]', ['mexico.txt']),\n",
       " ('bloc.', ['mexico.txt']),\n",
       " ('border', ['canada.txt']),\n",
       " ('border.', ['canada.txt']),\n",
       " ('bordered', ['mexico.txt']),\n",
       " ('britain', ['usa.txt']),\n",
       " ('british', ['canada.txt', 'usa.txt']),\n",
       " ('but', ['mexico.txt']),\n",
       " ('by', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('cabinet', ['canada.txt']),\n",
       " ('canada', ['canada.txt', 'usa.txt']),\n",
       " (\"canada's\", ['canada.txt']),\n",
       " ('capita', ['usa.txt']),\n",
       " ('capital', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('caribbean', ['mexico.txt']),\n",
       " ('catholic', ['mexico.txt']),\n",
       " ('ceded', ['canada.txt']),\n",
       " ('central', ['usa.txt']),\n",
       " ('centuries', ['usa.txt']),\n",
       " ('century,', ['canada.txt', 'usa.txt']),\n",
       " ('century.', ['usa.txt']),\n",
       " ('chair', ['canada.txt']),\n",
       " ('chiefly', ['canada.txt']),\n",
       " ('church', ['mexico.txt']),\n",
       " ('church,', ['mexico.txt']),\n",
       " ('city', ['mexico.txt', 'usa.txt']),\n",
       " ('city,', ['mexico.txt']),\n",
       " ('city,[12]', ['mexico.txt']),\n",
       " ('city.', ['usa.txt']),\n",
       " ('ciudad', ['mexico.txt']),\n",
       " ('civil', ['canada.txt', 'usa.txt']),\n",
       " ('civilization;[14]', ['mexico.txt']),\n",
       " ('civilizations,', ['mexico.txt']),\n",
       " ('coast.', ['canada.txt', 'usa.txt']),\n",
       " ('cold', ['usa.txt']),\n",
       " ('collapse', ['usa.txt']),\n",
       " ('colonies', ['canada.txt', 'usa.txt']),\n",
       " ('colonization', ['usa.txt']),\n",
       " ('colonization.', ['canada.txt']),\n",
       " ('colonized', ['mexico.txt']),\n",
       " ('commonly', ['usa.txt']),\n",
       " ('commonwealth', ['canada.txt']),\n",
       " ('communities,', ['mexico.txt']),\n",
       " ('competed', ['usa.txt']),\n",
       " ('complex', ['canada.txt']),\n",
       " ('comprising', ['mexico.txt']),\n",
       " ('confederation,', ['canada.txt']),\n",
       " ('confirmed', ['usa.txt']),\n",
       " ('conflict', ['mexico.txt']),\n",
       " ('conflicts,', ['canada.txt']),\n",
       " ('conquered', ['mexico.txt']),\n",
       " ('consensus', ['mexico.txt']),\n",
       " ('consequence', ['canada.txt']),\n",
       " ('considered', ['mexico.txt']),\n",
       " ('consists', ['usa.txt']),\n",
       " ('constitution', ['mexico.txt']),\n",
       " ('constitution.', ['mexico.txt']),\n",
       " ('constitutional', ['canada.txt']),\n",
       " ('constitutionalist', ['mexico.txt']),\n",
       " ('contiguous', ['mexico.txt']),\n",
       " ('continent.[21]', ['usa.txt']),\n",
       " ('continues', ['mexico.txt', 'usa.txt']),\n",
       " ('converted.', ['mexico.txt']),\n",
       " ('cooperation', ['canada.txt']),\n",
       " ('council.', ['usa.txt']),\n",
       " ('countries.', ['canada.txt']),\n",
       " ('country', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('country,', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('country.[29]', ['usa.txt']),\n",
       " ('covering', ['canada.txt']),\n",
       " ('covers', ['mexico.txt']),\n",
       " ('cradles', ['mexico.txt']),\n",
       " ('crime;', ['mexico.txt']),\n",
       " ('culminated', ['canada.txt']),\n",
       " ('culminating', ['usa.txt']),\n",
       " ('cultural,', ['usa.txt']),\n",
       " ('culture.', ['canada.txt']),\n",
       " ('curtailed', ['mexico.txt']),\n",
       " ('d.c.,', ['usa.txt']),\n",
       " ('deaths.[33]', ['mexico.txt']),\n",
       " ('decades', ['mexico.txt']),\n",
       " ('democracy', ['canada.txt']),\n",
       " ('democracy.', ['usa.txt']),\n",
       " ('dependence', ['canada.txt']),\n",
       " ('deposits', ['mexico.txt']),\n",
       " ('despite', ['usa.txt']),\n",
       " ('develop', ['usa.txt']),\n",
       " ('developed', ['canada.txt', 'usa.txt']),\n",
       " ('developing', ['mexico.txt']),\n",
       " ('development', ['canada.txt', 'mexico.txt']),\n",
       " ('development,', ['usa.txt']),\n",
       " ('dictatorship', ['mexico.txt']),\n",
       " ('disparities,', ['usa.txt']),\n",
       " ('displacing', ['usa.txt']),\n",
       " ('disputes', ['usa.txt']),\n",
       " ('district,', ['usa.txt']),\n",
       " ('diverse', ['canada.txt', 'usa.txt']),\n",
       " ('domestic', ['usa.txt']),\n",
       " ('dominated', ['mexico.txt']),\n",
       " ('dominion', ['canada.txt']),\n",
       " ('drafted', ['mexico.txt']),\n",
       " ('drug', ['mexico.txt']),\n",
       " ('during', ['usa.txt']),\n",
       " ('díaz,', ['mexico.txt']),\n",
       " ('east', ['mexico.txt', 'usa.txt']),\n",
       " ('ecologically', ['mexico.txt']),\n",
       " ('economic', ['canada.txt', 'mexico.txt']),\n",
       " ('economy', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('economy,', ['mexico.txt']),\n",
       " ('education.', ['canada.txt']),\n",
       " ('emerged', ['usa.txt']),\n",
       " ('emerging', ['mexico.txt']),\n",
       " ('emperor', ['mexico.txt']),\n",
       " ('empire', ['mexico.txt']),\n",
       " ('end', ['usa.txt']),\n",
       " ('ended', ['mexico.txt']),\n",
       " ('enshrined', ['mexico.txt']),\n",
       " ('established', ['usa.txt']),\n",
       " ('estados', ['mexico.txt']),\n",
       " ('estimated', ['usa.txt']),\n",
       " ('ethnically', ['canada.txt', 'usa.txt']),\n",
       " ('eum', ['mexico.txt']),\n",
       " ('european', ['canada.txt', 'usa.txt']),\n",
       " ('every', ['mexico.txt']),\n",
       " ('exile.', ['mexico.txt']),\n",
       " ('expanded', ['usa.txt']),\n",
       " ('expeditions', ['canada.txt']),\n",
       " ('exploited', ['mexico.txt']),\n",
       " ('explored', ['canada.txt']),\n",
       " ('exporter', ['usa.txt']),\n",
       " ('extend', ['canada.txt']),\n",
       " ('extensive', ['mexico.txt']),\n",
       " ('faction', ['mexico.txt']),\n",
       " ('federal', ['canada.txt', 'usa.txt']),\n",
       " ('federation', ['mexico.txt']),\n",
       " ('first', ['mexico.txt', 'usa.txt']),\n",
       " ('five', ['usa.txt']),\n",
       " ('following', ['mexico.txt']),\n",
       " ('for', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('force', ['usa.txt']),\n",
       " ('foremost', ['usa.txt']),\n",
       " ('formation', ['mexico.txt']),\n",
       " ('formed', ['canada.txt']),\n",
       " ('forum.', ['canada.txt']),\n",
       " ('founding', ['usa.txt']),\n",
       " ('four', ['canada.txt']),\n",
       " ('fourth-largest', ['usa.txt']),\n",
       " ('france', ['canada.txt', 'mexico.txt']),\n",
       " ('francophonie', ['canada.txt']),\n",
       " ('freedom,', ['canada.txt']),\n",
       " ('french', ['canada.txt', 'mexico.txt']),\n",
       " ('from', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('fund,', ['usa.txt']),\n",
       " ('g20,', ['canada.txt', 'mexico.txt']),\n",
       " ('g7,', ['canada.txt']),\n",
       " ('g8+5,', ['mexico.txt']),\n",
       " ('gdp', ['mexico.txt']),\n",
       " ('gdp,', ['usa.txt']),\n",
       " ('generals', ['mexico.txt']),\n",
       " ('global', ['mexico.txt', 'usa.txt']),\n",
       " ('globally', ['canada.txt']),\n",
       " ('goods,', ['usa.txt']),\n",
       " ('government', ['canada.txt', 'mexico.txt']),\n",
       " ('government.', ['canada.txt']),\n",
       " ('gradually', ['usa.txt']),\n",
       " ('granted', ['mexico.txt']),\n",
       " ('great', ['usa.txt']),\n",
       " ('gross', ['usa.txt']),\n",
       " ('group', ['canada.txt', 'mexico.txt']),\n",
       " ('groupings', ['canada.txt']),\n",
       " ('guadalajara,', ['mexico.txt']),\n",
       " ('guatemala,', ['mexico.txt']),\n",
       " ('gulf', ['mexico.txt']),\n",
       " ('habsburg', ['mexico.txt']),\n",
       " ('had', ['canada.txt']),\n",
       " ('half', ['usa.txt']),\n",
       " ('has', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('have', ['usa.txt']),\n",
       " ('head', ['canada.txt']),\n",
       " ('heavily', ['mexico.txt']),\n",
       " ('held', ['usa.txt']),\n",
       " ('heritage', ['mexico.txt']),\n",
       " ('high', ['usa.txt']),\n",
       " ('highest', ['canada.txt']),\n",
       " ('highlighted', ['canada.txt']),\n",
       " ('highly', ['usa.txt']),\n",
       " ('holds', ['usa.txt']),\n",
       " ('home', ['mexico.txt']),\n",
       " ('however,', ['mexico.txt']),\n",
       " ('huge', ['mexico.txt']),\n",
       " ('human', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('humans', ['usa.txt']),\n",
       " ('i', ['usa.txt']),\n",
       " ('identified', ['mexico.txt']),\n",
       " ('ii.', ['usa.txt']),\n",
       " ('immigration', ['canada.txt']),\n",
       " ('immigration.', ['usa.txt']),\n",
       " ('impact', ['canada.txt']),\n",
       " ('important', ['mexico.txt']),\n",
       " ('importer', ['usa.txt']),\n",
       " ('in', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('include', ['mexico.txt']),\n",
       " ('including', ['canada.txt', 'usa.txt']),\n",
       " ('income', ['canada.txt', 'usa.txt']),\n",
       " ('income,', ['usa.txt']),\n",
       " ('increasing', ['canada.txt']),\n",
       " ('independence', ['mexico.txt']),\n",
       " ('independence.[20]', ['usa.txt']),\n",
       " ('independent', ['mexico.txt']),\n",
       " ('index,', ['mexico.txt']),\n",
       " ('index.', ['canada.txt']),\n",
       " ('index.[32]', ['mexico.txt']),\n",
       " ('indigenous', ['canada.txt', 'mexico.txt']),\n",
       " ('industrialized', ['mexico.txt']),\n",
       " ('inequalities,', ['mexico.txt']),\n",
       " ('inhabitants', ['mexico.txt']),\n",
       " ('inhabitants,[4]', ['mexico.txt']),\n",
       " ('inhabited', ['canada.txt']),\n",
       " ('instability', ['mexico.txt']),\n",
       " ('installed', ['mexico.txt']),\n",
       " ('instituted', ['mexico.txt']),\n",
       " ('institutional', ['mexico.txt']),\n",
       " ('institutions', ['canada.txt']),\n",
       " ('intergovernmental', ['canada.txt']),\n",
       " ('international', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('internationally.[33]', ['usa.txt']),\n",
       " ('intervention.', ['mexico.txt']),\n",
       " ('into', ['canada.txt']),\n",
       " ('is', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('it', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('its', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('juárez', ['mexico.txt']),\n",
       " ('juárez,', ['mexico.txt']),\n",
       " ('kept', ['mexico.txt']),\n",
       " ('killing', ['usa.txt']),\n",
       " ('kilometers', ['mexico.txt']),\n",
       " ('kilometres', ['canada.txt']),\n",
       " ('kingdom.', ['canada.txt']),\n",
       " ('km2),', ['usa.txt']),\n",
       " ('known', ['mexico.txt', 'usa.txt']),\n",
       " ('land', ['canada.txt']),\n",
       " ('landed', ['usa.txt']),\n",
       " ('languages:', ['mexico.txt']),\n",
       " ('large', ['mexico.txt']),\n",
       " ('large-scale', ['canada.txt']),\n",
       " ('largest', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('lasting', ['usa.txt']),\n",
       " ('late', ['usa.txt']),\n",
       " ('later', ['canada.txt']),\n",
       " ('lead', ['mexico.txt']),\n",
       " ('leading', ['usa.txt']),\n",
       " ('least', ['usa.txt']),\n",
       " ('led', ['mexico.txt', 'usa.txt']),\n",
       " ('left', ['usa.txt']),\n",
       " ('legal', ['canada.txt', 'usa.txt']),\n",
       " ('level.', ['canada.txt']),\n",
       " ('león.[13]', ['mexico.txt']),\n",
       " ('liberties,', ['canada.txt']),\n",
       " ('life,', ['canada.txt']),\n",
       " ('located', ['usa.txt']),\n",
       " ('long', ['canada.txt']),\n",
       " ('longest', ['canada.txt']),\n",
       " ('losses', ['mexico.txt']),\n",
       " ('mainland', ['usa.txt']),\n",
       " ('major', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('make', ['mexico.txt']),\n",
       " ('making', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('many', ['canada.txt', 'mexico.txt']),\n",
       " ('marked', ['mexico.txt']),\n",
       " ('material,', ['mexico.txt']),\n",
       " ('maximilian', ['mexico.txt']),\n",
       " ('maya', ['mexico.txt']),\n",
       " ('measurements', ['canada.txt']),\n",
       " ('measures', ['usa.txt']),\n",
       " ('median', ['usa.txt']),\n",
       " ('megadiverse', ['mexico.txt']),\n",
       " ('member', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('mesoamerican', ['mexico.txt']),\n",
       " ('metropolis.', ['mexico.txt']),\n",
       " ('metropolitan', ['canada.txt']),\n",
       " ('mexican', ['mexico.txt']),\n",
       " ('mexicanos;', ['mexico.txt']),\n",
       " ('mexican–american', ['mexico.txt']),\n",
       " ('mexico', ['mexico.txt']),\n",
       " (\"mexico's\", ['mexico.txt']),\n",
       " ('mexico.', ['usa.txt']),\n",
       " ('mexico.[10]', ['mexico.txt']),\n",
       " ('mexiˈkanos]', ['mexico.txt']),\n",
       " ('mi),', ['canada.txt']),\n",
       " ('mi)[11]', ['mexico.txt']),\n",
       " ('middle', ['mexico.txt']),\n",
       " ('migrated', ['usa.txt']),\n",
       " ('miles', ['usa.txt']),\n",
       " ('miles),', ['canada.txt']),\n",
       " ('military', ['mexico.txt', 'usa.txt']),\n",
       " ('million', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('million,[7]', ['usa.txt']),\n",
       " ('millions', ['mexico.txt']),\n",
       " ('mine', ['mexico.txt']),\n",
       " ('minister', ['canada.txt']),\n",
       " ('mission,', ['usa.txt']),\n",
       " ('modernize', ['mexico.txt']),\n",
       " ('monarch', ['canada.txt']),\n",
       " ('monarchy', ['canada.txt']),\n",
       " ('monetary', ['usa.txt']),\n",
       " ('monterrey,', ['mexico.txt']),\n",
       " ('montreal,', ['canada.txt']),\n",
       " ('moon.', ['usa.txt']),\n",
       " ('more', ['usa.txt']),\n",
       " ('most', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('most-visited', ['mexico.txt']),\n",
       " ('mostly', ['usa.txt']),\n",
       " ('multicultural', ['canada.txt']),\n",
       " ('méxico', ['mexico.txt']),\n",
       " ('mēxihco),', ['mexico.txt']),\n",
       " ('nahuan', ['mexico.txt']),\n",
       " ('nation', ['mexico.txt']),\n",
       " ('nation.', ['mexico.txt']),\n",
       " ('nations', ['mexico.txt', 'usa.txt']),\n",
       " ('nations,', ['canada.txt', 'usa.txt']),\n",
       " ('native', ['usa.txt']),\n",
       " ('nato,', ['canada.txt', 'usa.txt']),\n",
       " ('natural', ['canada.txt', 'mexico.txt']),\n",
       " ('nearly', ['canada.txt']),\n",
       " ('networks.', ['canada.txt']),\n",
       " ('new', ['mexico.txt', 'usa.txt']),\n",
       " ('newly', ['mexico.txt']),\n",
       " ('nominal', ['canada.txt', 'mexico.txt']),\n",
       " ('north', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('north,', ['mexico.txt']),\n",
       " ('northern', ['canada.txt', 'mexico.txt']),\n",
       " ('northward', ['canada.txt']),\n",
       " ('now', ['canada.txt']),\n",
       " ('nuclear', ['usa.txt']),\n",
       " ('number', ['mexico.txt']),\n",
       " ('numerous', ['usa.txt']),\n",
       " ('obregón', ['mexico.txt']),\n",
       " ('ocean,', ['canada.txt']),\n",
       " ('ocean;', ['mexico.txt']),\n",
       " ('of', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('officially', ['canada.txt', 'mexico.txt']),\n",
       " ('often', ['mexico.txt']),\n",
       " ('on', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('one', ['canada.txt', 'mexico.txt']),\n",
       " ('one-party', ['mexico.txt']),\n",
       " ('only', ['usa.txt']),\n",
       " ('opposing', ['mexico.txt']),\n",
       " ('or', ['canada.txt', 'usa.txt']),\n",
       " ('order.[16]', ['mexico.txt']),\n",
       " ('organization', ['mexico.txt', 'usa.txt']),\n",
       " ('organizations.', ['usa.txt']),\n",
       " ('origins', ['mexico.txt']),\n",
       " ('other', ['canada.txt', 'mexico.txt', 'usa.txt']),\n",
       " ('ottawa,', ['canada.txt']),\n",
       " ('outcome', ['usa.txt']),\n",
       " ('over', ['mexico.txt', 'usa.txt']),\n",
       " ('pacific', ['canada.txt', 'mexico.txt']),\n",
       " ('paleo-indians', ['usa.txt']),\n",
       " ('parliament.', ['canada.txt']),\n",
       " ('parliamentary', ['canada.txt']),\n",
       " ('part', ['canada.txt']),\n",
       " ('partner.[25][26]', ['mexico.txt']),\n",
       " ('party', ['mexico.txt']),\n",
       " ('peace', ['mexico.txt']),\n",
       " ('peoples', ['canada.txt']),\n",
       " ('per', ['usa.txt']),\n",
       " ('per-capita', ['canada.txt']),\n",
       " ('performance,', ['usa.txt']),\n",
       " ('permanent', ['usa.txt']),\n",
       " ('played', ['mexico.txt']),\n",
       " ('political,', ['usa.txt']),\n",
       " ('politics', ['mexico.txt']),\n",
       " ('poorly', ['mexico.txt']),\n",
       " ('populated', ['mexico.txt'])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_and_words.map(lambda x: (x[1], set([x[0]])))\\\n",
    "              .reduceByKey(lambda x,y: x.union(y))\\\n",
    "              .sortByKey()\\\n",
    "              .mapValues(list).take(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use case (part 2)\n",
    "\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "<li>Print the list of unique parks where trees were treated, ordered alphabetically. Tip: use the <code>distinct</code> and <code>sortBy</code> transformations described in the <a href=\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\">Spark documentation</a>.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['60E AVENUE / SUD 4E RUE',\n",
       " '<Null>',\n",
       " 'AHUNTSIC',\n",
       " 'AHUNTSIC, PONT',\n",
       " 'ALBERT-PERRAS',\n",
       " 'ALEXANDER (S12)',\n",
       " 'ALEXIS-CARREL',\n",
       " 'ALEXIS-NIHON']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees2015.filter(lambda x: x[6])\\\n",
    "         .map(lambda x: x[6])\\\n",
    "         .distinct().sortBy(lambda x: x).take(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Create an RDD containing elements in the form <code>park,count</code>, where <code>count</code> is the number of trees treated in park <code>park</code>. Tip: use a logic similar to WordCount's.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GATIEN-CLAUDE, RUE', 2),\n",
       " ('BEAU-BOIS (OUEST DE BEAU-BOIS)', 3),\n",
       " ('BASILE-ROUTHIER', 12),\n",
       " ('J.-J.-GAGNIER', 2),\n",
       " ('GABRIEL-LALEMANT', 3),\n",
       " ('AHUNTSIC', 32),\n",
       " ('AHUNTSIC, PONT', 2),\n",
       " ('SAINT-SIMON-APÔTRE', 5)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees2015.filter(lambda x: x[6])\\\n",
    "         .map(lambda x: (x[6], 1))\\\n",
    "         .reduceByKey(lambda x, y: x+y).take(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Optional__\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "<li>Print the list of the 10 parks with the highest number of treated trees, ordered by decreasing count of treated trees. Tip: start from the solution to the previous question.</li></ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JEAN-DRAPEAU', 453),\n",
       " ('MAISONNEUVE, DE', 296),\n",
       " ('MONT-ROYAL', 235),\n",
       " ('JARRY', 170),\n",
       " ('COMPLEXE ENVIRONNEM. ST-MICHEL', 128),\n",
       " ('NOËL-SUD', 121),\n",
       " ('PROMENADE-BELLERIVE, DE LA', 104),\n",
       " ('ANGRIGNON', 103),\n",
       " ('Alexis-Carrel', 83),\n",
       " ('PHILIPPE-LAHEURTE', 79)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees2015.filter(lambda x: x[6])\\\n",
    "         .map(lambda x: (x[6], 1))\\\n",
    "         .reduceByKey(lambda x, y: x+y)\\\n",
    "         .sortBy(lambda x: x[1], ascending=False)\\\n",
    "         .take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " __Optional__\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>\n",
    " Print the alphabetically sorted list\n",
    "        of parks that had trees treated both in 2016 and 2015. Tip: use the <code>intersection</code> transformation.\n",
    "    </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATWATER, MARCHÉ PUBLIC',\n",
       " 'BERTRAND, PARC',\n",
       " 'Espace Vert Bertrand',\n",
       " 'Nom_parc']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parks2015 = trees2015.filter(lambda x: x[6])\\\n",
    "                     .map(lambda x: x[6])\n",
    "parks2016 = trees2016.filter(lambda x: x[6])\\\n",
    "                     .map(lambda x: x[6])\n",
    "both = parks2015.intersection(parks2016)\n",
    "both.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The MapReduce programming model was first introduced in Apache Spark:  \n",
    "    \n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x25a2; False\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The MapReduce programming model was first introduced in Apache Spark:  \n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x2611; False\n",
    "</div>\n",
    "\n",
    "The MapReduce programming model was first published by <a href=\"https://dl.acm.org/doi/abs/10.1145/1327452.1327492?casa_token=esUvbIYGBBQAAAAA:N9ZCfs4QQ8o4-4nIPw8gsr5smdwkbNQfz5v7IYM_PLwibvM3PLxUYi8jj_eBYWHgc--Zd5reHaSOHQ\">Google in 2008</a>, and the first public implementation was made available in <a href=\"https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html\">Apache Hadoop</a>. Compared to the Hadoop implementation, Spark provides:\n",
    "- An easier programming model, including APIs in Python, Java, Scala and R\n",
    "- Lazy evaluation (see next key concept)\n",
    "- In-memory computing (see next key concept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The map transformation is parallel: provided that enough computers are available in the cluster, partitions of an RDD will be processed concurrently by the map function:\n",
    "\n",
    "&#x25a2; True\n",
    "    \n",
    "&#x25a2; False\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The map transformation is parallel: provided that enough computers are available in the cluster, partitions of an RDD will be processed concurrently by the map function:\n",
    "    \n",
    "&#x2611; True\n",
    "    \n",
    "&#x25a2; False\n",
    "</div>\n",
    "\n",
    "The map transformation is, with filter, the main parallelization construct in Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The reduce transformation may result in important overheads due to data transfers:  \n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x25a2; False\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "A reduce transformation may result in important overheads due to data transfers:  \n",
    "    \n",
    "&#x2611; True\n",
    "    \n",
    "&#x25a2; False\n",
    "</div>\n",
    "\n",
    "A <code>reduceByKey</code> or <code>groupByKey</code> transformation combines data from many partitions of the RDD, which can result in important data transfers. They should be used with care!\n",
    "\n",
    "<img src=\"images/session1/wide-narrow.png\" alt=\"narrow-wide\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Spark is limited to the processing of textual data. Binary data types, such as signals or images, are not supported:\n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x25a2; False\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Spark is limited to the processing of textual data. Binary data types, such as signals or images, are not supported:\n",
    "    \n",
    "&#x25a2; True\n",
    "    \n",
    "&#x2611; False\n",
    "</div>\n",
    "\n",
    "RDDs can be created from binary data, in particular using `sc.binaryFile`. Complete frameworks have also been built over Spark to process images or signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Key concept 3: Data locality, Lazy evaluation, In-memory computing\n",
    "\n",
    "## Data locality\n",
    "\n",
    "Data transfers can be an important source of overhead in a distributed environment. \n",
    "\n",
    "To limit data movement, Spark:\n",
    "- schedules tasks preferably to the nodes where input data is located (HDFS helps)\n",
    "- leaves output data on the nodes where it was produced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <b>The effect of data locality <a href=\"https://arxiv.org/pdf/1812.06492\">[Hayot-Sasson <i>et al.</i>, 2019]</a></b>\n",
    "<img src=\"images/session1/data-locality.png\"/>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Impact of data locality is maximal for <b>data-intensive</b> applications\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lazy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "When an action is called, Spark combines transformations to avoid unnecessary computations. \n",
    "    </div>\n",
    "\n",
    "\n",
    "<img src=\"images/session1/lazy.png\" alt=\"lazy evaluation\" width=800/>\n",
    "(diagram by Valérie Hayot-Sasson)\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In-memory computing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Spark keeps data in memory as much as possible, which makes it faster than Hadoop MapReduce\n",
    "    </div>\n",
    "\n",
    "    \n",
    "<img src=\"images/session1/memory.png\" alt=\"in memory benchmark\"/>\n",
    "\n",
    "<a href=\"https://www.usenix.org/conference/nsdi12/technical-sessions/presentation/zaharia\">[Zaharia <i>et al.</i>, 2012]</a>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Key concept 4: DataFrames\n",
    "\n",
    "## Creating and manipulating DataFrames\n",
    "\n",
    "\n",
    "Similar to R or Pandas, Spark can also manipulate data through DataFrames representing textual tables. \n",
    "\n",
    "The DataFrame API requires to initialize a Spark session from Spark's SQL API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The DataFrame API is particularly suited for the processing of CSV files, as is the case of our use case. CSV files can be loaded as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------+----------------+--------------+----------------+--------+------+----------+------------------+-------------------+-----------------+----------------+\n",
      "|          Nom_arrond|Invent|No_Civiq|             Rue|        Rue_De|           Rue_a|Nom_parc| Sigle|Injections|                 x|                  y|        longitude|        latitude|\n",
      "+--------------------+------+--------+----------------+--------------+----------------+--------+------+----------+------------------+-------------------+-----------------+----------------+\n",
      "|Ahuntsic-Cartierv...|     R|   10265|Rue Saint-Hubert| SAURIOL E RUE|    FLEURY E RUE|    null|FRPESU|      2015|292338.75000000000|5046268.50000000000|-73.6596113879546|45.5562169952192|\n",
      "|Ahuntsic-Cartierv...|     R|    9451|     Rue Foucher|CHABANEL E RUE|LOUVAIN E RUE DE|    null|FRAMKL|      2015|293090.71899999998|5045715.50000000000|-73.6499665032798|45.5512539761596|\n",
      "|Ahuntsic-Cartierv...|     R|   10435|       Rue Taché|   TACHÉ PLACE|    PRIEUR E RUE|    null|  FRPE|      2015|292521.68199999997|5047302.00000000000|-73.6572942384626|45.5655199930171|\n",
      "+--------------------+------+--------+----------------+--------------+----------------+--------+------+----------+------------------+-------------------+-----------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/session1/frenepublicinjection2015.csv'\n",
    "df = spark.read.option(\"header\",\"true\").csv(filename)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas data frames are more nicely rendered in Jupyter than Spark's, so for the sake of visualization we can convert our Spark DataFrame to Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom_arrond</th>\n",
       "      <th>Invent</th>\n",
       "      <th>No_Civiq</th>\n",
       "      <th>Rue</th>\n",
       "      <th>Rue_De</th>\n",
       "      <th>Rue_a</th>\n",
       "      <th>Nom_parc</th>\n",
       "      <th>Sigle</th>\n",
       "      <th>Injections</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahuntsic-Cartierville</td>\n",
       "      <td>R</td>\n",
       "      <td>10265</td>\n",
       "      <td>Rue Saint-Hubert</td>\n",
       "      <td>SAURIOL E RUE</td>\n",
       "      <td>FLEURY E RUE</td>\n",
       "      <td>None</td>\n",
       "      <td>FRPESU</td>\n",
       "      <td>2015</td>\n",
       "      <td>292338.75000000000</td>\n",
       "      <td>5046268.50000000000</td>\n",
       "      <td>-73.6596113879546</td>\n",
       "      <td>45.5562169952192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahuntsic-Cartierville</td>\n",
       "      <td>R</td>\n",
       "      <td>9451</td>\n",
       "      <td>Rue Foucher</td>\n",
       "      <td>CHABANEL E RUE</td>\n",
       "      <td>LOUVAIN E RUE DE</td>\n",
       "      <td>None</td>\n",
       "      <td>FRAMKL</td>\n",
       "      <td>2015</td>\n",
       "      <td>293090.71899999998</td>\n",
       "      <td>5045715.50000000000</td>\n",
       "      <td>-73.6499665032798</td>\n",
       "      <td>45.5512539761596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahuntsic-Cartierville</td>\n",
       "      <td>R</td>\n",
       "      <td>10435</td>\n",
       "      <td>Rue Taché</td>\n",
       "      <td>TACHÉ PLACE</td>\n",
       "      <td>PRIEUR E RUE</td>\n",
       "      <td>None</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>292521.68199999997</td>\n",
       "      <td>5047302.00000000000</td>\n",
       "      <td>-73.6572942384626</td>\n",
       "      <td>45.5655199930171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahuntsic-Cartierville</td>\n",
       "      <td>R</td>\n",
       "      <td>1475</td>\n",
       "      <td>Rue Prieur Est</td>\n",
       "      <td>OLYMPIA BOULE</td>\n",
       "      <td>HAMEL AVENU</td>\n",
       "      <td>None</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>292325.89710000000</td>\n",
       "      <td>5047059.65600000040</td>\n",
       "      <td>-73.6597961939526</td>\n",
       "      <td>45.5633358284252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahuntsic-Cartierville</td>\n",
       "      <td>R</td>\n",
       "      <td>9905</td>\n",
       "      <td>Avenue du Sacré-Coeur</td>\n",
       "      <td>SAUVÉ E RUE</td>\n",
       "      <td>SAURIOL E RUE</td>\n",
       "      <td>None</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>292839.26500000001</td>\n",
       "      <td>5046594.00000000000</td>\n",
       "      <td>-73.6532084656865</td>\n",
       "      <td>45.5591547231261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21909</th>\n",
       "      <td>PARCS-NATURE</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MONT-ROYAL</td>\n",
       "      <td>FR</td>\n",
       "      <td>2015</td>\n",
       "      <td>297437.74040000001</td>\n",
       "      <td>5039933.67190000040</td>\n",
       "      <td>-73.5942052885376</td>\n",
       "      <td>45.4992863950936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21910</th>\n",
       "      <td>PARCS-NATURE</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MONT-ROYAL</td>\n",
       "      <td>FR</td>\n",
       "      <td>2015</td>\n",
       "      <td>297561.81050000002</td>\n",
       "      <td>5041162.75330000000</td>\n",
       "      <td>-73.5926358640406</td>\n",
       "      <td>45.5103474786451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21911</th>\n",
       "      <td>PARCS-NATURE</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MONT-ROYAL</td>\n",
       "      <td>FR</td>\n",
       "      <td>2015</td>\n",
       "      <td>297647.50740000000</td>\n",
       "      <td>5041122.03110000030</td>\n",
       "      <td>-73.5915385046076</td>\n",
       "      <td>45.5099819278503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21912</th>\n",
       "      <td>PARCS-NATURE</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MONT-ROYAL</td>\n",
       "      <td>FR</td>\n",
       "      <td>2015</td>\n",
       "      <td>297635.04790000001</td>\n",
       "      <td>5041121.26140000020</td>\n",
       "      <td>-73.5916979514118</td>\n",
       "      <td>45.5099748738842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21913</th>\n",
       "      <td>PARCS-NATURE</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MONT-ROYAL</td>\n",
       "      <td>FR</td>\n",
       "      <td>2015</td>\n",
       "      <td>297636.15429999999</td>\n",
       "      <td>5041124.62880000010</td>\n",
       "      <td>-73.5916838407805</td>\n",
       "      <td>45.5100051864881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21914 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Nom_arrond Invent No_Civiq                    Rue  \\\n",
       "0      Ahuntsic-Cartierville      R    10265       Rue Saint-Hubert   \n",
       "1      Ahuntsic-Cartierville      R     9451            Rue Foucher   \n",
       "2      Ahuntsic-Cartierville      R    10435              Rue Taché   \n",
       "3      Ahuntsic-Cartierville      R     1475         Rue Prieur Est   \n",
       "4      Ahuntsic-Cartierville      R     9905  Avenue du Sacré-Coeur   \n",
       "...                      ...    ...      ...                    ...   \n",
       "21909           PARCS-NATURE      H     None                   None   \n",
       "21910           PARCS-NATURE      H     None                   None   \n",
       "21911           PARCS-NATURE      H     None                   None   \n",
       "21912           PARCS-NATURE      H     None                   None   \n",
       "21913           PARCS-NATURE      H     None                   None   \n",
       "\n",
       "               Rue_De             Rue_a    Nom_parc   Sigle Injections  \\\n",
       "0       SAURIOL E RUE      FLEURY E RUE        None  FRPESU       2015   \n",
       "1      CHABANEL E RUE  LOUVAIN E RUE DE        None  FRAMKL       2015   \n",
       "2         TACHÉ PLACE      PRIEUR E RUE        None    FRPE       2015   \n",
       "3       OLYMPIA BOULE       HAMEL AVENU        None    FRPE       2015   \n",
       "4         SAUVÉ E RUE     SAURIOL E RUE        None    FRPE       2015   \n",
       "...               ...               ...         ...     ...        ...   \n",
       "21909            None              None  MONT-ROYAL      FR       2015   \n",
       "21910            None              None  MONT-ROYAL      FR       2015   \n",
       "21911            None              None  MONT-ROYAL      FR       2015   \n",
       "21912            None              None  MONT-ROYAL      FR       2015   \n",
       "21913            None              None  MONT-ROYAL      FR       2015   \n",
       "\n",
       "                        x                    y          longitude  \\\n",
       "0      292338.75000000000  5046268.50000000000  -73.6596113879546   \n",
       "1      293090.71899999998  5045715.50000000000  -73.6499665032798   \n",
       "2      292521.68199999997  5047302.00000000000  -73.6572942384626   \n",
       "3      292325.89710000000  5047059.65600000040  -73.6597961939526   \n",
       "4      292839.26500000001  5046594.00000000000  -73.6532084656865   \n",
       "...                   ...                  ...                ...   \n",
       "21909  297437.74040000001  5039933.67190000040  -73.5942052885376   \n",
       "21910  297561.81050000002  5041162.75330000000  -73.5926358640406   \n",
       "21911  297647.50740000000  5041122.03110000030  -73.5915385046076   \n",
       "21912  297635.04790000001  5041121.26140000020  -73.5916979514118   \n",
       "21913  297636.15429999999  5041124.62880000010  -73.5916838407805   \n",
       "\n",
       "               latitude  \n",
       "0      45.5562169952192  \n",
       "1      45.5512539761596  \n",
       "2      45.5655199930171  \n",
       "3      45.5633358284252  \n",
       "4      45.5591547231261  \n",
       "...                 ...  \n",
       "21909  45.4992863950936  \n",
       "21910  45.5103474786451  \n",
       "21911  45.5099819278503  \n",
       "21912  45.5099748738842  \n",
       "21913  45.5100051864881  \n",
       "\n",
       "[21914 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Spark DataFrames leverage RDDs. In fact, the internal representation of a DataFrame is an RDD, which can be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Nom_arrond='Ahuntsic-Cartierville', Invent='R', No_Civiq='10265', Rue='Rue Saint-Hubert', Rue_De='SAURIOL E RUE', Rue_a='FLEURY E RUE', Nom_parc=None, Sigle='FRPESU', Injections='2015', x='292338.75000000000', y='5046268.50000000000', longitude='-73.6596113879546', latitude='45.5562169952192'),\n",
       " Row(Nom_arrond='Ahuntsic-Cartierville', Invent='R', No_Civiq='9451', Rue='Rue Foucher', Rue_De='CHABANEL E RUE', Rue_a='LOUVAIN E RUE DE', Nom_parc=None, Sigle='FRAMKL', Injections='2015', x='293090.71899999998', y='5045715.50000000000', longitude='-73.6499665032798', latitude='45.5512539761596'),\n",
       " Row(Nom_arrond='Ahuntsic-Cartierville', Invent='R', No_Civiq='10435', Rue='Rue Taché', Rue_De='TACHÉ PLACE', Rue_a='PRIEUR E RUE', Nom_parc=None, Sigle='FRPE', Injections='2015', x='292521.68199999997', y='5047302.00000000000', longitude='-73.6572942384626', latitude='45.5655199930171')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Several functions are available to process DataFrames, documented [here](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame). \n",
    "\n",
    "Here are a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21914"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom_arrond</th>\n",
       "      <th>Invent</th>\n",
       "      <th>No_Civiq</th>\n",
       "      <th>Rue</th>\n",
       "      <th>Rue_De</th>\n",
       "      <th>Rue_a</th>\n",
       "      <th>Nom_parc</th>\n",
       "      <th>Sigle</th>\n",
       "      <th>Injections</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>PARC BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296260.14159999997</td>\n",
       "      <td>5041800.16899999980</td>\n",
       "      <td>-73.6093059696596</td>\n",
       "      <td>45.5160684743449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>PARC BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296319.74300000002</td>\n",
       "      <td>5041754.97950000040</td>\n",
       "      <td>-73.6085423208117</td>\n",
       "      <td>45.515662568851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296272.35879999999</td>\n",
       "      <td>5041816.35859999990</td>\n",
       "      <td>-73.6091498774581</td>\n",
       "      <td>45.5162143042545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296288.98060000001</td>\n",
       "      <td>5041831.09619999960</td>\n",
       "      <td>-73.608937382347</td>\n",
       "      <td>45.5163471220592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296306.81589999999</td>\n",
       "      <td>5041836.73049999960</td>\n",
       "      <td>-73.6087091962244</td>\n",
       "      <td>45.5163980391792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296412.50150000001</td>\n",
       "      <td>5041706.05559999960</td>\n",
       "      <td>-73.6073542313963</td>\n",
       "      <td>45.5152234542308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296420.52789999999</td>\n",
       "      <td>5041710.43479999990</td>\n",
       "      <td>-73.607251574014</td>\n",
       "      <td>45.5152629565036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296442.08000000002</td>\n",
       "      <td>5041716.70660000020</td>\n",
       "      <td>-73.6069758291288</td>\n",
       "      <td>45.5153196513007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296472.87890000001</td>\n",
       "      <td>5041736.81869999970</td>\n",
       "      <td>-73.6065819659723</td>\n",
       "      <td>45.515500996407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296457.00709999999</td>\n",
       "      <td>5041746.40799999980</td>\n",
       "      <td>-73.6067852779769</td>\n",
       "      <td>45.5155870949897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296443.76260000002</td>\n",
       "      <td>5041753.07010000010</td>\n",
       "      <td>-73.6069549128558</td>\n",
       "      <td>45.5156468845987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296424.47810000001</td>\n",
       "      <td>5041770.70179999990</td>\n",
       "      <td>-73.6072020439008</td>\n",
       "      <td>45.5158053102171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296409.13620000001</td>\n",
       "      <td>5041777.30059999970</td>\n",
       "      <td>-73.6073985243323</td>\n",
       "      <td>45.5158645043691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296376.41800000001</td>\n",
       "      <td>5041734.32909999970</td>\n",
       "      <td>-73.6078165604713</td>\n",
       "      <td>45.5154774353769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296358.52450000000</td>\n",
       "      <td>5041808.28550000020</td>\n",
       "      <td>-73.608046859169</td>\n",
       "      <td>45.5161427078129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296335.98979999998</td>\n",
       "      <td>5041821.42690000030</td>\n",
       "      <td>-73.6083355189657</td>\n",
       "      <td>45.5162606861193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296351.43849999999</td>\n",
       "      <td>5041686.86730000000</td>\n",
       "      <td>-73.6081354638508</td>\n",
       "      <td>45.5150500531465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296323.93930000003</td>\n",
       "      <td>5041698.95490000020</td>\n",
       "      <td>-73.6084876420413</td>\n",
       "      <td>45.515158488419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296311.42400000000</td>\n",
       "      <td>5041677.68759999980</td>\n",
       "      <td>-73.6086474605726</td>\n",
       "      <td>45.5149669646084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296235.87969999999</td>\n",
       "      <td>5041705.78249999970</td>\n",
       "      <td>-73.6096148604724</td>\n",
       "      <td>45.5152188498757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Outremont</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>296263.64409999998</td>\n",
       "      <td>5041699.83500000000</td>\n",
       "      <td>-73.6092593922999</td>\n",
       "      <td>45.515165672372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rosemont - La Petite-Patrie</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>297765.36770000000</td>\n",
       "      <td>5045949.98139999990</td>\n",
       "      <td>-73.5900994559228</td>\n",
       "      <td>45.5534268279842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rosemont - La Petite-Patrie</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>297774.76699999999</td>\n",
       "      <td>5045967.70780000000</td>\n",
       "      <td>-73.5899793245344</td>\n",
       "      <td>45.553586431033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rosemont - La Petite-Patrie</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BEAUBIEN</td>\n",
       "      <td>FRPE</td>\n",
       "      <td>2015</td>\n",
       "      <td>297747.32130000001</td>\n",
       "      <td>5045906.47979999990</td>\n",
       "      <td>-73.5903299665362</td>\n",
       "      <td>45.5530352032757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Nom_arrond Invent No_Civiq            Rue Rue_De Rue_a  \\\n",
       "0                     Outremont      H     None  PARC BEAUBIEN   None  None   \n",
       "1                     Outremont      H     None  PARC BEAUBIEN   None  None   \n",
       "2                     Outremont      H     None           None   None  None   \n",
       "3                     Outremont      H     None       BEAUBIEN   None  None   \n",
       "4                     Outremont      H     None       BEAUBIEN   None  None   \n",
       "5                     Outremont      H     None       BEAUBIEN   None  None   \n",
       "6                     Outremont      H     None       BEAUBIEN   None  None   \n",
       "7                     Outremont      H     None       BEAUBIEN   None  None   \n",
       "8                     Outremont      H     None       BEAUBIEN   None  None   \n",
       "9                     Outremont      H     None       BEAUBIEN   None  None   \n",
       "10                    Outremont      H     None       BEAUBIEN   None  None   \n",
       "11                    Outremont      H     None       BEAUBIEN   None  None   \n",
       "12                    Outremont      H     None       BEAUBIEN   None  None   \n",
       "13                    Outremont      H     None       BEAUBIEN   None  None   \n",
       "14                    Outremont      H     None       BEAUBIEN   None  None   \n",
       "15                    Outremont      H     None           None   None  None   \n",
       "16                    Outremont      H     None       BEAUBIEN   None  None   \n",
       "17                    Outremont      H     None       BEAUBIEN   None  None   \n",
       "18                    Outremont      H     None       BEAUBIEN   None  None   \n",
       "19                    Outremont      H     None       BEAUBIEN   None  None   \n",
       "20                    Outremont      H     None       BEAUBIEN   None  None   \n",
       "21  Rosemont - La Petite-Patrie      H     None           None   None  None   \n",
       "22  Rosemont - La Petite-Patrie      H     None           None   None  None   \n",
       "23  Rosemont - La Petite-Patrie      H     None           None   None  None   \n",
       "\n",
       "    Nom_parc Sigle Injections                   x                    y  \\\n",
       "0   BEAUBIEN  FRPE       2015  296260.14159999997  5041800.16899999980   \n",
       "1   BEAUBIEN  FRPE       2015  296319.74300000002  5041754.97950000040   \n",
       "2   BEAUBIEN  FRPE       2015  296272.35879999999  5041816.35859999990   \n",
       "3   BEAUBIEN  FRPE       2015  296288.98060000001  5041831.09619999960   \n",
       "4   BEAUBIEN  FRPE       2015  296306.81589999999  5041836.73049999960   \n",
       "5   BEAUBIEN  FRPE       2015  296412.50150000001  5041706.05559999960   \n",
       "6   BEAUBIEN  FRPE       2015  296420.52789999999  5041710.43479999990   \n",
       "7   BEAUBIEN  FRPE       2015  296442.08000000002  5041716.70660000020   \n",
       "8   BEAUBIEN  FRPE       2015  296472.87890000001  5041736.81869999970   \n",
       "9   BEAUBIEN  FRPE       2015  296457.00709999999  5041746.40799999980   \n",
       "10  BEAUBIEN  FRPE       2015  296443.76260000002  5041753.07010000010   \n",
       "11  BEAUBIEN  FRPE       2015  296424.47810000001  5041770.70179999990   \n",
       "12  BEAUBIEN  FRPE       2015  296409.13620000001  5041777.30059999970   \n",
       "13  BEAUBIEN  FRPE       2015  296376.41800000001  5041734.32909999970   \n",
       "14  BEAUBIEN  FRPE       2015  296358.52450000000  5041808.28550000020   \n",
       "15  BEAUBIEN  FRPE       2015  296335.98979999998  5041821.42690000030   \n",
       "16  BEAUBIEN  FRPE       2015  296351.43849999999  5041686.86730000000   \n",
       "17  BEAUBIEN  FRPE       2015  296323.93930000003  5041698.95490000020   \n",
       "18  BEAUBIEN  FRPE       2015  296311.42400000000  5041677.68759999980   \n",
       "19  BEAUBIEN  FRPE       2015  296235.87969999999  5041705.78249999970   \n",
       "20  BEAUBIEN  FRPE       2015  296263.64409999998  5041699.83500000000   \n",
       "21  BEAUBIEN  FRPE       2015  297765.36770000000  5045949.98139999990   \n",
       "22  BEAUBIEN  FRPE       2015  297774.76699999999  5045967.70780000000   \n",
       "23  BEAUBIEN  FRPE       2015  297747.32130000001  5045906.47979999990   \n",
       "\n",
       "            longitude          latitude  \n",
       "0   -73.6093059696596  45.5160684743449  \n",
       "1   -73.6085423208117   45.515662568851  \n",
       "2   -73.6091498774581  45.5162143042545  \n",
       "3    -73.608937382347  45.5163471220592  \n",
       "4   -73.6087091962244  45.5163980391792  \n",
       "5   -73.6073542313963  45.5152234542308  \n",
       "6    -73.607251574014  45.5152629565036  \n",
       "7   -73.6069758291288  45.5153196513007  \n",
       "8   -73.6065819659723   45.515500996407  \n",
       "9   -73.6067852779769  45.5155870949897  \n",
       "10  -73.6069549128558  45.5156468845987  \n",
       "11  -73.6072020439008  45.5158053102171  \n",
       "12  -73.6073985243323  45.5158645043691  \n",
       "13  -73.6078165604713  45.5154774353769  \n",
       "14   -73.608046859169  45.5161427078129  \n",
       "15  -73.6083355189657  45.5162606861193  \n",
       "16  -73.6081354638508  45.5150500531465  \n",
       "17  -73.6084876420413   45.515158488419  \n",
       "18  -73.6086474605726  45.5149669646084  \n",
       "19  -73.6096148604724  45.5152188498757  \n",
       "20  -73.6092593922999   45.515165672372  \n",
       "21  -73.5900994559228  45.5534268279842  \n",
       "22  -73.5899793245344   45.553586431033  \n",
       "23  -73.5903299665362  45.5530352032757  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering\n",
    "df.filter(df['Nom_parc'] == 'BEAUBIEN').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use case (part 3): with DataFrames\n",
    "\n",
    "We will now repeat the analyses done on our dataset, this time with the DataFrame API.\n",
    "\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "<li>Using the DataFrame API, print the list of unique parks where trees were treated, ordered alphabetically. Tip: use the <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.select\"><code>select</code></a> function.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Nom_parc|\n",
      "+--------------------+\n",
      "|60E AVENUE / SUD ...|\n",
      "|              <Null>|\n",
      "|            AHUNTSIC|\n",
      "|      AHUNTSIC, PONT|\n",
      "|       ALBERT-PERRAS|\n",
      "|     ALEXANDER (S12)|\n",
      "|       ALEXIS-CARREL|\n",
      "|        ALEXIS-NIHON|\n",
      "| ALLÉE DES TANNERIES|\n",
      "|ALPHONSE-TELESHPO...|\n",
      "|ALPHONSE-TELESPHO...|\n",
      "|ANCIENNE-COUR-DE-...|\n",
      "|  ANCIENNE-PÉPINIÈRE|\n",
      "|           ANGRIGNON|\n",
      "|      APPRENTIS, DES|\n",
      "| AQUEDUC DE MONTRÉAL|\n",
      "|      ARMAND-VANASSE|\n",
      "|ATWATER, MARCHÉ P...|\n",
      "|     AUTOPARC NO 088|\n",
      "|     AUTOPARC NO 266|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Nom_parc'] != '')\\\n",
    "  .select('Nom_parc')\\\n",
    "  .distinct()\\\n",
    "  .orderBy('Nom_parc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Using the DataFrame API, print a list of elements in the form <code>park,count</code>, where <code>count</code> is the number of trees treated in park <code>park</code>. Tip: use function <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.groupBy\"><code>groupBy</code></a>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Nom_parc|count|\n",
      "+--------------------+-----+\n",
      "|60E AVENUE / SUD ...|    2|\n",
      "|              <Null>|   14|\n",
      "|            AHUNTSIC|   32|\n",
      "|      AHUNTSIC, PONT|    2|\n",
      "|       ALBERT-PERRAS|   11|\n",
      "|     ALEXANDER (S12)|   22|\n",
      "|       ALEXIS-CARREL|    1|\n",
      "|        ALEXIS-NIHON|   23|\n",
      "| ALLÉE DES TANNERIES|    1|\n",
      "|ALPHONSE-TELESHPO...|    1|\n",
      "|ALPHONSE-TELESPHO...|    1|\n",
      "|ANCIENNE-COUR-DE-...|    5|\n",
      "|  ANCIENNE-PÉPINIÈRE|    8|\n",
      "|           ANGRIGNON|  103|\n",
      "|      APPRENTIS, DES|    5|\n",
      "| AQUEDUC DE MONTRÉAL|    9|\n",
      "|      ARMAND-VANASSE|    7|\n",
      "|ATWATER, MARCHÉ P...|    8|\n",
      "|     AUTOPARC NO 088|    6|\n",
      "|     AUTOPARC NO 266|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Nom_parc'] != '')\\\n",
    "  .select('Nom_parc')\\\n",
    "  .groupBy('Nom_parc')\\\n",
    "  .count()\\\n",
    "  .orderBy('Nom_parc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Optional__\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "<li>Print the list of the 10 parks with the highest number of treated trees, ordered by decreasing count of treated trees. Tip: start from the solution to the previous question.</li></ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Nom_parc|count|\n",
      "+--------------------+-----+\n",
      "|        JEAN-DRAPEAU|  453|\n",
      "|     MAISONNEUVE, DE|  296|\n",
      "|          MONT-ROYAL|  235|\n",
      "|               JARRY|  170|\n",
      "|COMPLEXE ENVIRONN...|  128|\n",
      "|            NOËL-SUD|  121|\n",
      "|PROMENADE-BELLERI...|  104|\n",
      "|           ANGRIGNON|  103|\n",
      "|       Alexis-Carrel|   83|\n",
      "|   PHILIPPE-LAHEURTE|   79|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Nom_parc'] != '')\\\n",
    "  .select('Nom_parc')\\\n",
    "  .groupBy('Nom_parc')\\\n",
    "  .count()\\\n",
    "  .orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " __Optional__\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>\n",
    " Print the alphabetically sorted list\n",
    "    of parks that had trees treated both in 2016 and 2015. Tip: use the <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.join\"><code>join</code></a> function.\n",
    "    </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Nom_parc|\n",
      "+--------------------+\n",
      "|Espace Vert Bertrand|\n",
      "|      BERTRAND, PARC|\n",
      "|ATWATER, MARCHÉ P...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames\n",
    "\n",
    "filename1 = 'data/session1/frenepublicinjection2015.csv'\n",
    "df1 = spark.read.option(\"header\",\"true\").csv(filename1).select('Nom_parc').distinct()\n",
    "\n",
    "filename2 = 'data/session1/frenepublicinjection2016.csv'\n",
    "df2 = spark.read.option(\"header\",\"true\").csv(filename2).select('Nom_parc').distinct()\n",
    "\n",
    "# Join them on Nom_parc\n",
    "df1.join(df2, df1['Nom_parc'] == df2['Nom_parc'])\\\n",
    "   .select(df1['Nom_parc']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    &#x2611; <i>when</i> to use Spark\n",
    "</div>\n",
    "\n",
    "<i>Large datasets, substantial processing, independent tasks, batch processing</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    &#x2611; <i>how</i> to write Spark programs\n",
    "</div>\n",
    "\n",
    "<i>Two APIs: Resilient Distributed Datasets, DataFrames</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    &#x2611; <i>what</i> is the relation between Spark and <i>Hadoop</i>\n",
    "</div>\n",
    "\n",
    "<i>Hadoop MapReduce was the first public implementation of MapReduce. Spark now outperforms it and provides a simpler API.</i>\n",
    "\n",
    "<i>The Hadoop Distributed File System (HDFS) can be combined with Spark to improve data locality.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <b>The Apache Spark ecosystem <a href=\"https://dl.acm.org/doi/fullHtml/10.1145/2934664\">[Zaharia <i>et al.</i>, 2016]</a></b>\n",
    "<img src=\"images/session1/ecosystem.png\" alt=\"ecosystem\" width=600/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "360.717px",
    "left": "1528.05px",
    "top": "33.1333px",
    "width": "369.95px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
