{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"background:black\">\n",
    "    <center>\n",
    "<img src=\"./images/session3/title.png\" alt=\"Title\"/>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<center>\n",
    "Today's objectives:<br/><br/>\n",
    "    </center>\n",
    "    &#x25a2; Get familiar with <b>supervised classification</b><br/>\n",
    "    &#x25a2; Try <b>Spark's MLlib classification</b> library <br/>\n",
    "    &#x25a2; Apply supervised classification to <b>network intrusion detection</b><br/>\n",
    "    &#x25a2; Practice with Spark <b>DataFrames</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Principles of supervised classification\n",
    "\n",
    "See slides [here](pdf/session3/classification.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised classification in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  <div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "Spark has a rich API for Classification and Regression, described <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html\">here<a>\n",
    "        </center>\n",
    "        </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will go through an example adapted from https://spark.apache.org/docs/latest/ml-classification-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# A little magic to adjust the config at Ericsson\n",
    "import os\n",
    "os.environ[\"IPYTHON\"]=\"1\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"ipython3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]=\"notebook\"\n",
    "os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/default-java\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The data is already prepared for MLlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"data/session3/sample_libsvm_data.txt\")\n",
    "\n",
    "# Convert to Pandas for better visualization in notebook\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once data is prepared, first step is to split the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "print(f'Dataset has {data.count()} elements')\n",
    "print(f'Training set has {trainingData.count()} elements')\n",
    "print(f'Test set has {testData.count()} elements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  <div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "    The <b>Pipeline</b> is an important element of MLlib, containing the various transformations and models applied to the data.\n",
    "    </center>\n",
    "    </div>\n",
    "    <a id=\"pipeline\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Define a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "# Chain data preparation and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "<li>Using your knowledge the DataFrame API, compute the accuracy of this classifier on the test set:</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quiz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Deep Learning can be used for supervised classification:\n",
    "    \n",
    "&#x25a2; True\n",
    "\n",
    "&#x25a2; False\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Decision trees can be used for regression:\n",
    "    \n",
    "&#x25a2; True\n",
    "\n",
    "&#x25a2; False\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Classifiers in Spark's MLlib are all parallelized, they could leverage a computing cluster:\n",
    "    \n",
    "&#x25a2; True\n",
    "\n",
    "&#x25a2; False\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mini-project: network intrusion detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Goal</b>: predict if a network connection is an attack\n",
    "    </div>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Data inspection\n",
    "\n",
    "Data: US Air Force LAN data ([link](https://www.kaggle.com/sampadab17/network-intrusion-detection)), available in <code>data/session3/network_data.csv</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "! head data/session3/network_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data loading\n",
    "\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Load the dataset as a Spark DataFrame:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>What are the categorical and numerical features?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data preparation (1 feature)\n",
    "<a id=\"preparation\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Required: a DataFrame with columns named <b>label</b> (numeric) and <b>features</b> (vector of numbers).\n",
    "    </div>\n",
    "    </center>\n",
    "    \n",
    "For clarity, we will first start with a single feature, <code>src_bytes</code>.\n",
    "\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Build a DataFrame called <code>data</code> containing only two columns: <code>src_bytes</code> and <code>class</code>. Tip: use function <code>select</code> in the DataFrame API.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Column <code>src_bytes</code> is of type <code>string</code> while a number is required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Module <b>pyspark.sql.functions</b> contains useful functions to manipulate DataFrames. \n",
    "</div>\n",
    "    Here we use function <code>col</code> to access a column from its name:\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Cast numeric columns to float\n",
    "from pyspark.sql.functions import col\n",
    "data = data.select([col('src_bytes').cast(\"float\") \n",
    "                    for col_name in data.columns if col_name != 'class'] + [ col('class') ])\n",
    "data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "We will now build our data transformation pipeline, that will:\n",
    "<ol>\n",
    "    <li>Encode column <code>class</code> as numbers</li>\n",
    "    <li>Build a feature vector from column <code>src_bytes</code></li>\n",
    "</ol>\n",
    "\n",
    "Here is the definition of the pipeline stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stages = []\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "label_stringIdx = StringIndexer(inputCol = 'class', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assemblerInputs = [c for c in data.columns if c != 'class' and c != 'label']\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "\n",
    "stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Apply these pipeline stages to <code>data</code>. Tip: use the example in <a href=\"#pipeline\">Section 2</a>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Split the transformed data into a training (70%) and a test (30%) set. Tip: use function <code>randomSplit</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Train a Random Forest classifier on the training set, and make predictions on the test set using the resulting model. Tip: use the example in <a href=\"#pipeline\">Section 2</a>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Compute the accuracy of your predictions.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    You should obtain an accuracy <b>slightly above 0.9</b>. That's quite good for a model trained on a single feature! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Optional</b>\n",
    "\n",
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Play with the analysis parameters (number of trees in the forest, train/test ratio) to see how they influence the prediction.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<center>\n",
    "    Obtaining such a high accuracy with a single feature is suspicious. \n",
    "</center>\n",
    "    <ol>\n",
    "    <li>Was information shared between the train and test sets?</li>\n",
    "    <li>Is the feature strongly correlated with the class label?</li>\n",
    "    </ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's plot the feature histogram for each class, using Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "anomalies = data.where(data['class'] == 'anomaly').toPandas()\n",
    "normals = data.where(data['class'] == 'normal').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "thresh = 500  # we won't plot beyond src_bytes=500\n",
    "bins = 40  # number of bins in the histograms\n",
    "\n",
    "# Plot histograms\n",
    "filtered_anomalies = [ x for x in anomalies.src_bytes if x < thresh ]\n",
    "plt.hist(filtered_anomalies, alpha=0.5, label='anomalies', bins=bins)\n",
    "\n",
    "filtered_normals = [ x for x in normals.src_bytes if x < thresh ]\n",
    "plt.hist(filtered_normals, alpha=0.5, label='normals', bins=bins)\n",
    "\n",
    "# Formatting\n",
    "plt.xlim(0, thresh)\n",
    "plt.xlabel('src_bytes')\n",
    "plt.ylabel('occurrences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<center>\n",
    "It looks like the large majority of anomalies have <code>src_bytes</code> less than 30. A simple threshold should give good classification performance.\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A threshold-based classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Starting from DataFrame <code>test</code>, create a <code>predictions</code> DataFrame where the prediction will be 1 (anomaly) if <code>src_bytes</code> &lt; 30, and 0 (normal) otherwise.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Compute the accuracy of this simple classifier.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<center>\n",
    "The accuracy is close to the one obtained from Random Forests.<br/>\n",
    "This reinforces our confidence in this result that initially looked too good to be true.\n",
    "</center>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<center>\n",
    "Many features remain unused, which suggests that our 0.9 accuracy result might still be improved. \n",
    "    </center>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Starting from the data preparation example in <a href=\"#preparation\">Section 4.3</a>, prepare the dataset to use all the <b>numerical</b> features. Don't include categorical features for now.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Split the dataset in train (70%) and test (30%) sets</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Fit a Random Forest classifier on the training set and use it to make predictions on the test set</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Evaluate the accuracy of your classifier</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<center>\n",
    "As expected, accuracy improved substantially by adding more features. <br/>\n",
    "    This won't always be the case, finding the best features is called <b>feature engineering</b>.\n",
    "</center>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<center>\n",
    "Categorical features need to be encoded as numbers to be used by Spark MLlib classifiers.<br/>Here we will use a popular encoding method called <b>one-hot encoding</b>.\n",
    "</center>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's re-load the data, cast the numerical features to floats, and index the class column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV data in a DataFrame\n",
    "filename = 'data/session3/network_data.csv'\n",
    "data = spark.read.option(\"header\",\"true\").csv(filename)\n",
    "    \n",
    "numeric_features = [ x for x in data.columns if x not in categorical_features and x != 'class' ]\n",
    "\n",
    "# Cast numeric columns to float\n",
    "from pyspark.sql.functions import col\n",
    "data = data.select([col(col_name).cast(\"float\") \n",
    "                    for col_name in data.columns if col_name != 'class' and col_name not in categorical_features]\\\n",
    "                   + [ col('class') ]\n",
    "                   + categorical_features)\n",
    "\n",
    "# Stages\n",
    "stages = []\n",
    "\n",
    "# Index class \n",
    "from pyspark.ml.feature import StringIndexer\n",
    "label_stringIdx = StringIndexer(inputCol = 'class', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will implement one-hot encoding by adding two steps to the MLlib pipeline, **for each categorical variable**:\n",
    "1. A ```StringIndexer```, to convert categorical values to integers\n",
    "2. A ```OneHotEncoder```, to represent these integers as non-ordinal bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Define the pipeline stages to transform categorical features using <code>StringIndexer</code> and <code>OneHotEncoder</code> from <code>pyspark.ml.feature</code></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Define the pipeline stage to create column <code>features</code> using <code>VectorAssembler</code> from <code>pyspark.ml.feature</code></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Apply the transformation pipeline to the dataset</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Split the dataset in train (70%) and test (30%) sets</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Fit a Random Forest classifier on the training set and use it to make predictions on the test set</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul style=\"list-style-image: url('images/do.png');\">\n",
    "    <li>Evaluate the accuracy of your classifier</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<center>\n",
    "Not much improvement was brought by categorical variables\n",
    "</center>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<center>\n",
    "    </center>\n",
    "    &#x2611; Get familiar with <b>supervised classification</b><br/>\n",
    "    &#x2611; Try <b>Spark's MLlib classification</b> library <br/>\n",
    "    &#x2611; Apply supervised classification to <b>network intrusion detection</b><br/>\n",
    "    &#x2611; Practice with Spark <b>DataFrames</b>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
